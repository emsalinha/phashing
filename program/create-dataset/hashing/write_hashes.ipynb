{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "from PIL import Image, PngImagePlugin\n",
    "import glob\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold=25)\n",
    "import scipy.fftpack\n",
    "import pandas as pd\n",
    "import time\n",
    "import h5py\n",
    "start = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hash(frame_path, hash_size, high_freq_factor):\n",
    "    im = Image.open(frame_path).convert(\"RGB\") \n",
    "    img_size = hash_size * high_freq_factor\n",
    "    image = im.convert(\"L\").resize((img_size, img_size), Image.ANTIALIAS)\n",
    "    pixels = np.asarray(image)\n",
    "    dct = scipy.fftpack.dct(scipy.fftpack.dct(pixels, axis=0), axis=1)\n",
    "    dctlowfreq = dct[:hash_size, :hash_size]\n",
    "    med = np.median(dctlowfreq)\n",
    "    diff = dctlowfreq > med\n",
    "    phash = [1 if x == True else 0 for x in diff.flatten()]\n",
    "    return phash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_hashes_to_csv(path_film, wd_hashes, frame_paths, annotation):\n",
    "    film_name = glob.glob(path_film)[0].split('/')[-1].replace(' ', '-')[0:7]\n",
    "    hashes = [get_hash(frame, hash_size, high_freq_factor) for frame in frame_paths]\n",
    "    film_names = [film_name] * len(frame_paths)\n",
    "    frame_names = [frame.split('/')[-1].split('.')[0] for frame in frame_paths]\n",
    "    \n",
    "    data = {'film_name': film_names,\n",
    "        'frame': frame_names,\n",
    "       'hash': hashes,\n",
    "           'annotation': annotation}\n",
    "    dataset = pd.DataFrame.from_dict(data)\n",
    "    dataset.to_csv(wd_hashes + '{}-hashes-{}-{}.csv'.format(film_name, hash_size, high_freq_factor), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_size = 15\n",
    "high_freq_factor = 4\n",
    "\n",
    "n_film = 3\n",
    "wd_frames = os.getcwd() + '/films/film_{}/frames/'.format(n_film)\n",
    "frame_paths = sorted(glob.glob(wd_frames + '*'))\n",
    "\n",
    "path_film = os.getcwd() + '/films/film_{}/film/*'.format(n_film)\n",
    "wd_hashes = os.getcwd() + '/films/film_{}/hashes/'.format(n_film)\n",
    "\n",
    "dataset['annotation'] = np.random.choice(2, len(dataset.hash))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'frame_paths' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-32e92f16ee3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwrite_hashes_to_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_film\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd_hashes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'frame_paths' is not defined"
     ]
    }
   ],
   "source": [
    "write_hashes_to_csv(path_film, wd_hashes, frame_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_elementwise_hdf5(frame_paths, size_hash, hash_size = 15, high_freq_factor = 4, name = ''):\n",
    "    n_frames = len(frame_paths)\n",
    "    \n",
    "    hdf5_store = h5py.File(\"./phashes{}.hdf5\".format('_'+name), \"a\")\n",
    "    phashes = hdf5_store.create_dataset(\"phashes\", (n_frames, size_hash), compression=\"gzip\")\n",
    "\n",
    "    for i in range(0, n_frames):\n",
    "        frame_path = frame_paths[i]\n",
    "        phash = get_hash(frame_path, hash_size, high_freq_factor)\n",
    "        phashes[i] = phash\n",
    "        \n",
    "def write_batchwise_hdf5(frame_paths, size_hash, hash_size = 15, high_freq_factor = 4, name = ''):\n",
    "    n_frames = len(frame_paths)\n",
    "    \n",
    "    hdf5_store = h5py.File(\"./phashes{}.hdf5\".format('_'+name), \"a\")\n",
    "    phashes = np.zeros((n_frames, size_hash))\n",
    "\n",
    "    \n",
    "    for i in range(0, n_frames):\n",
    "        frame_path = frame_paths[i]\n",
    "        phash = get_hash(frame_path, hash_size, high_freq_factor)\n",
    "        phashes[i] = phash\n",
    "\n",
    "    hdf5_store.create_dataset(\"phashes\", data = phashes, compression=\"gzip\")\n",
    "\n",
    "def test_writing_speed_hdf5():\n",
    "    start = time.time()\n",
    "    write_elementwise(trailer_frames, 122)\n",
    "    end = time.time()\n",
    "    print('time for elementwise writing', end-start)\n",
    "    #time for elementwise writing 42.066429138183594\n",
    "\n",
    "    start = time.time()\n",
    "    write_batchwise(trailer_frames, 122)\n",
    "    end = time.time()\n",
    "    print('time for batch writing', end-start)\n",
    "    # time for batch writing 38.23404669761658\n",
    "\n",
    "def write_hashes_to_hdf5(frame_paths, hash_size = 15, high_freq_factor = 4, name =  ''):\n",
    "    size_hash = len(get_hash(frame_paths[0], hash_size, high_freq_factor))\n",
    "    write_elementwise_hdf5(frame_paths, size_hash, hash_size, high_freq_factor, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time for elementwise writing 43.02076053619385\n"
     ]
    }
   ],
   "source": [
    "write_hashes_to_hdf5(trailer_frames, name = 'trailer')\n",
    "write_hashes_to_hdf5(frames, name = 'movie')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
