{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "from PIL import Image, PngImagePlugin\n",
    "import glob\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold=25)\n",
    "import scipy.fftpack\n",
    "import pandas as pd\n",
    "import time\n",
    "import h5py\n",
    "start = time.time()\n",
    "\n",
    "hash_size = 15\n",
    "high_freq_factor = 4\n",
    "\n",
    "wd_frames = '/home/emsala/Documenten/Studie/These/phashing/dataset/films/film_1/frames/*'\n",
    "frames = sorted(glob.glob(wd_frames))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trailer_frames(frames):\n",
    "    def zero_padding_numbers(frame_name, len_number=4, frame_nr = False):\n",
    "        if frame_nr == False:\n",
    "            frame_nr = frame_name.split('frame')[1].split('.')[0]\n",
    "            start = frame_name.split(frame_nr)[0]\n",
    "            end = frame_name.split(frame_nr)[1]\n",
    "        else:\n",
    "            start = ''\n",
    "            frame_nr = str(frame_name)\n",
    "            end = ''\n",
    "        len_padding = len_number-len(frame_nr)\n",
    "        new_nr = ('0'*len_padding) + frame_nr\n",
    "        new_name = start + new_nr + end\n",
    "        return new_name\n",
    "\n",
    "    shot1 = list(range(840, 1508))\n",
    "    shot2 = list(range(1528, 1911))\n",
    "    shot3 = list(range(2611, 2674))\n",
    "    shot4 = list(range(3280, 3461))\n",
    "    shot5 = list(range(4453, 4612))\n",
    "\n",
    "    shots = shot1 + shot2 + shot3 + shot4 + shot5\n",
    "    shot_numbers = [zero_padding_numbers(shot, frame_nr = True) for shot in shots]\n",
    "    correct_frames = ['frame{}.jpg'.format(shot_number) for shot_number in shot_numbers]\n",
    "    trailer_frames = [frame for frame in frames if frame.split('/')[-1] in correct_frames]    \n",
    "    return trailer_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hash(frame_path, hash_size, high_freq_factor):\n",
    "    im = Image.open(frame_path).convert(\"RGB\") \n",
    "    img_size = hash_size * high_freq_factor\n",
    "    image = im.convert(\"L\").resize((img_size, img_size), Image.ANTIALIAS)\n",
    "    pixels = np.asarray(image)\n",
    "    dct = scipy.fftpack.dct(scipy.fftpack.dct(pixels, axis=0), axis=1)\n",
    "    dctlowfreq = dct[:hash_size, :hash_size]\n",
    "    med = np.median(dctlowfreq)\n",
    "    diff = dctlowfreq > med\n",
    "    phash = [1 if x == True else 0 for x in diff.flatten()]\n",
    "    return phash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_elementwise(frame_paths, size_hash, hash_size = 15, high_freq_factor = 4, name = ''):\n",
    "    n_frames = len(frame_paths)\n",
    "    \n",
    "    hdf5_store = h5py.File(\"./phashes{}.hdf5\".format('_'+name), \"a\")\n",
    "    phashes = hdf5_store.create_dataset(\"phashes\", (n_frames, size_hash), compression=\"gzip\")\n",
    "\n",
    "    for i in range(0, n_frames):\n",
    "        frame_path = frame_paths[i]\n",
    "        phash = get_hash(frame_path, hash_size, high_freq_factor)\n",
    "        phashes[i] = phash\n",
    "        \n",
    "def write_batchwise(frame_paths, size_hash, hash_size = 15, high_freq_factor = 4, name = ''):\n",
    "    n_frames = len(frame_paths)\n",
    "    \n",
    "    hdf5_store = h5py.File(\"./phashes{}.hdf5\".format('_'+name), \"a\")\n",
    "    phashes = np.zeros((n_frames, size_hash))\n",
    "\n",
    "    \n",
    "    for i in range(0, n_frames):\n",
    "        frame_path = frame_paths[i]\n",
    "        phash = get_hash(frame_path, hash_size, high_freq_factor)\n",
    "        phashes[i] = phash\n",
    "\n",
    "    hdf5_store.create_dataset(\"phashes\", data = phashes, compression=\"gzip\")\n",
    "\n",
    "def test_writing_speed():\n",
    "    start = time.time()\n",
    "    write_elementwise(trailer_frames, 122)\n",
    "    end = time.time()\n",
    "    print('time for elementwise writing', end-start)\n",
    "    #time for elementwise writing 42.066429138183594\n",
    "\n",
    "    start = time.time()\n",
    "    write_batchwise(trailer_frames, 122)\n",
    "    end = time.time()\n",
    "    print('time for batch writing', end-start)\n",
    "    # time for batch writing 38.23404669761658\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_hashes_to_hdf5(frame_paths, hash_size = 15, high_freq_factor = 4, name =  ''):\n",
    "    size_hash = len(get_hash(frame_paths[0], hash_size, high_freq_factor))\n",
    "    write_elementwise(frame_paths, size_hash, hash_size, high_freq_factor, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time for elementwise writing 43.02076053619385\n"
     ]
    }
   ],
   "source": [
    "write_hashes_to_hdf5(trailer_frames, name = 'trailer')\n",
    "write_hashes_to_hdf5(frames, name = 'movie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
